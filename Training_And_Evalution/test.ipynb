{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYljjVr_LUll",
    "outputId": "cd726067-f3ad-4996-acd5-db92797057b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 5.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 41.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 16.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 48.6 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 7.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
      "Collecting recordclass\n",
      "  Downloading recordclass-0.16.3.tar.gz (14.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.3 MB 5.3 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: recordclass\n",
      "  Building wheel for recordclass (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for recordclass: filename=recordclass-0.16.3-cp37-cp37m-linux_x86_64.whl size=359580 sha256=5785b86090a2775d5432b930e6a2b25b230681bcca80d87e1acd0ca41278da70\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/36/16/278ae4105ec94809ba788d7b5f85b5374fcd0b7c689e7d0a15\n",
      "Successfully built recordclass\n",
      "Installing collected packages: recordclass\n",
      "Successfully installed recordclass-0.16.3\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Untitled6.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1W8e4Hs79pu25biKKh9mK6h6-jE2XEGA1\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "#from pytorch_transformers import BertTokenizer, BertModel, AdamW\n",
    "!pip install transformers\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import os\n",
    "!pip install recordclass\n",
    "from recordclass import recordclass\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jN479Zms4QeY"
   },
   "outputs": [],
   "source": [
    "  def custom_print(*msg):\n",
    "    for i in range(0, len(msg)):\n",
    "        if i == len(msg) - 1:\n",
    "            print(msg[i])\n",
    "            logger.write(str(msg[i]) + '\\n')\n",
    "        else:\n",
    "            print(msg[i], ' ', end='')\n",
    "            logger.write(str(msg[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PdMT6XbQMNiF",
    "outputId": "3087913c-57c1-4b21-a345-46108b96b021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140  \t  23  \t  0.5\n",
      "32  \t  100\n",
      "LSTM\n",
      "loading data......\n",
      "Training data size:  1535\n",
      "Development data size:  330\n",
      "preparing vocabulary......\n",
      "vocab length:  5307\n",
      "embed dictionary length:  2738\n",
      "Training started......\n",
      "train_size\n",
      "1535\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters size:  12021367\n",
      "Seq2SeqModel(\n",
      "  (encoder): Encoder(\n",
      "    (bert_vec): BERT(\n",
      "      (bert): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (char_embeddings): CharEmbeddings(\n",
      "      (embeddings): Embedding(84, 50, padding_idx=0)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (lstm): LSTM(818, 150, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (conv1d): Conv1d(50, 50, kernel_size=(3,), stride=(1,))\n",
      "    (max_pool): MaxPool1d(kernel_size=12, stride=12, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention1): Attention(\n",
      "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
      "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
      "    )\n",
      "    (attention2): Attention(\n",
      "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
      "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
      "    )\n",
      "    (lstm): LSTMCell(3000, 300)\n",
      "    (trig_pointer_lstm): LSTM(600, 300, batch_first=True, bidirectional=True)\n",
      "    (ent_pointer_lstm): LSTM(1200, 300, batch_first=True, bidirectional=True)\n",
      "    (trigger_s_lin): Linear(in_features=600, out_features=1, bias=True)\n",
      "    (trigger_e_lin): Linear(in_features=600, out_features=1, bias=True)\n",
      "    (entity_s_lin): Linear(in_features=600, out_features=1, bias=True)\n",
      "    (entity_e_lin): Linear(in_features=600, out_features=1, bias=True)\n",
      "    (et_lin): Linear(in_features=2700, out_features=11, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (w): Linear(in_features=2400, out_features=300, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "weight factor:  1.0\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/48 [00:00<00:41,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/48 [00:01<00:24,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 3/48 [00:01<00:28,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/48 [00:02<00:25,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/48 [00:03<00:28,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 6/48 [00:03<00:28,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 7/48 [00:04<00:24,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 8/48 [00:05<00:27,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 9/48 [00:05<00:24,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11/48 [00:06<00:18,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 12/48 [00:06<00:16,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 13/48 [00:07<00:18,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 14/48 [00:07<00:15,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 15/48 [00:08<00:15,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 16/48 [00:08<00:14,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 17/48 [00:09<00:14,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 17/48 [00:09<00:17,  1.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4af162311e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mmodel_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_bert_19_10.h5py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#call train_model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4fa7fc9d1d01>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_id, train_samples, dev_samples, best_model_file)\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meType_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0met_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m   \u001b[0mwf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpointer_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1s\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpointer_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mwf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpointer_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2s\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpointer_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "random_seed=1023\n",
    "torch.manual_seed(random_seed)\n",
    "#set_random_seeds(random_seed)\n",
    "batch_size = 32\n",
    "num_epoch = 100\n",
    "model_name=1\n",
    "\n",
    "logger = open('training.log', 'w+')\n",
    "\n",
    "bert_base_size = 768\n",
    "update_bert = 0\n",
    "bert_model_name = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_basic_tokenize=False)\n",
    "\n",
    "max_src_len = 140#max sentence length = 135\n",
    "max_trg_len = 23#max number of tuple\n",
    "embedding_file = '/content/drive/MyDrive/w2v.txt'#pretrained word embeddings file\n",
    "word_embed_dim = 300\n",
    "word_min_freq = 2\n",
    "\n",
    "char_embed_dim = 50\n",
    "char_feature_size = 50\n",
    "\n",
    "pos_embed_dim=50\n",
    "\n",
    "conv_filter_size = 3\n",
    "max_word_len = 10\n",
    "positional_embed_dim = word_embed_dim\n",
    "#max_positional_idx = 100\n",
    "max_positional_idx = 140\n",
    "\n",
    "### Sample(Id=uid, SrcLen=len(src_words), SrcWords=src_words,TrgPointers=trg_pointers, eventTypes=trg_events)\n",
    "\n",
    "enc_inp_size = bert_base_size + char_feature_size\n",
    "enc_hidden_size = word_embed_dim\n",
    "dec_inp_size = enc_hidden_size\n",
    "dec_hidden_size = dec_inp_size\n",
    "\n",
    "drop_rate = 0.5\n",
    "enc_type = ['LSTM', 'GCN', 'LSTM-GCN'][0]\n",
    "\n",
    "att_type = 2\n",
    "wf = 1.0\n",
    "update_freq = 1\n",
    "use_hadamard = False\n",
    "early_stop_cnt = 7\n",
    "\n",
    "Sample = recordclass(\"Sample\", \"Id SrcLen SrcWords  eventTypes  TrgPointers  TrgLen\")\n",
    "\n",
    "event_file = '/content/event_names.txt'\n",
    "eventnameToIdx, eventIdxToName=get_events(event_file)#return event dictionary\n",
    "\n",
    "\n",
    "custom_print(max_src_len, '\\t', max_trg_len, '\\t', drop_rate)\n",
    "custom_print(batch_size, '\\t', num_epoch)\n",
    "custom_print(enc_type)\n",
    "custom_print('loading data......')\n",
    "\n",
    "src_train_file = '/content/train_bert.sent'\n",
    "trg_train_file = '/content/train_bert.pointer'\n",
    "#pos_train_file = 'train_bert.pos'\n",
    "\n",
    "train_data = read_data(src_train_file, trg_train_file, 1)#call read_data() for train_set\n",
    "\n",
    "src_dev_file = '/content/deb_bert.sent'\n",
    "trg_dev_file = '/content/deb_bert.pointer'\n",
    "#pos_dev_file = 'dev_bert.pos'\n",
    "dev_data = read_data(src_dev_file, trg_dev_file, 2)#call read_data() for dev_set\n",
    "\n",
    "src_test_file = '/content/test_bert.sent'\n",
    "trg_test_file = '/content/test_bert.pointer'\n",
    "#pos_test_file = 'test_bert.pos'\n",
    "test_data = read_data(src_test_file, trg_test_file, 3)#call read_data() for dev_set\n",
    "\n",
    "custom_print('Training data size:', len(train_data))\n",
    "custom_print('Development data size:', len(dev_data))\n",
    "\n",
    "custom_print(\"preparing vocabulary......\")\n",
    "save_vocab = '/content/vocab.pkl'\n",
    "\n",
    "word_vocab, char_vocab, word_embed_matrix = build_vocab(train_data, dev_data, test_data,save_vocab,embedding_file)#create vocabulary and word embeddings\n",
    "\n",
    "custom_print(\"Training started......\")\n",
    "\n",
    "model_name=1\n",
    "model_file_name = 'model_bert_19_10.h5py'\n",
    "\n",
    "train_model(model_name, train_data, dev_data, model_file_name)#call train_model()\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCauBjLt3p1H",
    "outputId": "c00325f7-d82e-4a5c-e602-3a5bc564a0b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fx9CSrolh4mB",
    "outputId": "0859410f-e4ac-494a-a7e6-639443432b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVhwnFQA3JHY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynUVYr1IAlMz"
   },
   "outputs": [],
   "source": [
    "!cp /content/model_bert_19_10.h5py /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlgW4H6C3LtC",
    "outputId": "8cf6e965-9cd4-459f-af5e-0c3a8d3b5589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('<PAD>', 0), ('Profit', 1), ('Dividend', 2), ('MergerAcquisition', 3), ('SalesVolume', 4), ('BuyRating', 5), ('QuarterlyResults', 6), ('TargetPrice', 7), ('ShareRepurchase', 8), ('Turnover', 9), ('Debt', 10)]) OrderedDict([('<PAD>', 0), ('Profit', 1), ('Dividend', 2), ('MergerAcquisition', 3), ('SalesVolume', 4), ('BuyRating', 5), ('QuarterlyResults', 6), ('TargetPrice', 7), ('ShareRepurchase', 8), ('Turnover', 9), ('Debt', 10)])\n",
      "140  \t  23  \t  0.5\n",
      "32  \t  100\n",
      "LSTM\n",
      "loading data......\n",
      "Training data size:  1535\n",
      "Development data size:  328\n",
      "preparing vocabulary......\n",
      "getting pos tags......\n",
      "vocab length:  5308\n",
      "embed dictionary length:  2739\n",
      "loading word vectors......\n",
      "vocab size:  2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqModel(\n",
      "  (encoder): Encoder(\n",
      "    (bert_vec): BERT(\n",
      "      (bert): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (char_embeddings): CharEmbeddings(\n",
      "      (embeddings): Embedding(85, 50, padding_idx=0)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (lstm): LSTM(818, 150, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (conv1d): Conv1d(50, 50, kernel_size=(3,), stride=(1,))\n",
      "    (max_pool): MaxPool1d(kernel_size=12, stride=12, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention1): Attention(\n",
      "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
      "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
      "    )\n",
      "    (attention2): Attention(\n",
      "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
      "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
      "    )\n",
      "    (lstm): LSTMCell(3000, 300)\n",
      "    (trig_pointer_lstm): LSTM(600, 300, batch_first=True, bidirectional=True)\n",
      "    (ent_pointer_lstm): LSTM(1200, 300, batch_first=True, bidirectional=True)\n",
      "    (trigger_s_lin): Linear(in_features=600, out_features=1, bias=True)\n",
      "    (trigger_e_lin): Linear(in_features=600, out_features=1, bias=True)\n",
      "    (entity_s_lin): Linear(in_features=600, out_features=1, bias=True)\n",
      "    (entity_e_lin): Linear(in_features=600, out_features=1, bias=True)\n",
      "    (et_lin): Linear(in_features=1500, out_features=11, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (w): Linear(in_features=2400, out_features=300, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "\n",
      "Test Results\n",
      "\n",
      "Test size:  330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:704: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:883: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:886: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:889: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:892: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 1/11 [00:01<00:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [00:02<00:09,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 3/11 [00:03<00:08,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 4/11 [00:04<00:07,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 5/11 [00:05<00:06,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 6/11 [00:06<00:05,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 7/11 [00:07<00:04,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 8/11 [00:08<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 9/11 [00:10<00:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([32, 2400])\n",
      "\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n",
      " yes torch.Size([32, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 10/11 [00:11<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      " yes torch.Size([10, 2400])\n",
      "\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n",
      " yes torch.Size([10, 2400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:11<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time:  0:00:11.819868\n",
      "340  \t  408  \t  51\n",
      "no of correctly identified triggers= 80\n",
      "no of correctly classified triggers= 70\n",
      "no of correctly identified arguments= 0\n",
      "no of correctly identified roles= 0\n",
      "P_tuple:  0.15\n",
      "P_ti:  0.235\n",
      "P_tc:  0.206\n",
      "P_ai:  0.0\n",
      "P_ro:  0.0\n",
      "R_tuple:  0.125\n",
      "R_ti:  0.196\n",
      "R_tc:  0.172\n",
      "R_ai:  0.0\n",
      "R_ro:  0.0\n",
      "F1:  0.136\n",
      "TI F1:  0.214\n",
      "TC F1:  0.187\n",
      "AI F1:  0.0\n",
      "RL F1:  0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "def custom_print(*msg):\n",
    "    for i in range(0, len(msg)):\n",
    "        if i == len(msg) - 1:\n",
    "            print(msg[i])\n",
    "            logger.write(str(msg[i]) + '\\n')\n",
    "        else:\n",
    "            print(msg[i], ' ', end='')\n",
    "            logger.write(str(msg[i]))\n",
    "\n",
    "\n",
    "def get_data(src_lines, trg_lines, datatype):\n",
    "    samples = []\n",
    "    uid = 1\n",
    "    for i in range(0, len(src_lines)):#for each line\n",
    "        src_line = src_lines[i].strip()\n",
    "        trg_line = trg_lines[i].strip()\n",
    "        src_words = src_line.split()\n",
    "        trg_events=[]#holds events present in a sentence\n",
    "        trg_pointers = []#holds tuples containg records per relation\n",
    "        parts = trg_line.split('|')\n",
    "\n",
    "        tuples_in=[]\n",
    "        for part in parts:\n",
    "            elements = part.strip().split()\n",
    "            tuples_in.append((int(elements[0]), int(elements[1]), eventnameToIdx[elements[2]], int(elements[3]), int(elements[4])))\n",
    "\n",
    "        if datatype ==1:\n",
    "            tuples_in = sorted(tuples_in, key = lambda element: (element[0], element[3]))\n",
    "        for elements in tuples_in:\n",
    "            trg_events.append(elements[2])#event index\n",
    "            trg_pointers.append((int(elements[0]), int(elements[1]), int(elements[3]), int(elements[4])))#all the records like event-start_index, end_index, entity- start_index, end_index\n",
    "\n",
    "        if datatype == 1 and (len(src_words) > max_src_len or len(trg_events) > max_trg_len):#if cross max_sentence_length or max_trg_length(max no of relation tuples present in the sentence)\n",
    "            continue\n",
    "\n",
    "        sample = Sample(Id=uid, SrcLen=len(src_words), SrcWords=src_words, TrgLen=len(trg_events),\n",
    "                        TrgPointers=trg_pointers, eventTypes=trg_events)#recordclass(\"Sample\", \"Id SrcLen SrcWords TrgLen TrgRels eventTypes argTypes TrgPointers\")\n",
    "        samples.append(sample)\n",
    "        uid += 1\n",
    "\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "# In[113]:\n",
    "\n",
    "def read_data(src_file, trg_file, datatype):  ###, pos_dev_file\n",
    "    reader = open(src_file)\n",
    "    src_lines = reader.readlines()\n",
    "    reader.close()\n",
    "\n",
    "    reader = open(trg_file)\n",
    "    trg_lines = reader.readlines()\n",
    "    reader.close()\n",
    "    data = get_data(src_lines, trg_lines, datatype)#call get_data()\n",
    "    return data#list of records, records are of type Sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[114]:\n",
    "\n",
    "\n",
    "def get_events(file_name):\n",
    "    nameToIdx = OrderedDict()#dictionary{key=name. value=idx}\n",
    "    idxToName = OrderedDict()#dictionary{key=idx, value=name}\n",
    "    reader = open(file_name)\n",
    "    lines = reader.readlines()\n",
    "    reader.close()\n",
    "    nameToIdx['<PAD>'] = 0\n",
    "    idxToName[0] = '<PAD>'\n",
    "    # nameToIdx['<SOS>'] = 1\n",
    "    # idxToName[1] = '<SOS>'\n",
    "    #nameToIdx['None'] = 1\n",
    "    #idxToName[1] = 'None'\n",
    "    idx = 1\n",
    "    for line in lines:\n",
    "        nameToIdx[line.strip()] = idx\n",
    "        idxToName[idx] = line.strip()\n",
    "        idx += 1\n",
    "    return nameToIdx, idxToName\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[115]:\n",
    "\n",
    "def is_full_match(triplet, triplets):\n",
    "    for t in triplets:\n",
    "        if t[0] == triplet[0] and t[1] == triplet[1] and t[2] == triplet[2] :\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "# In[116]:\n",
    "\n",
    "\n",
    "def get_gt_triples(src_words, pointers, event_list):\n",
    "    touples = []\n",
    "    i = 0\n",
    "\n",
    "    for e in event_list:\n",
    "        arg1 = ' '.join(src_words[pointers[i][0]:pointers[i][1] + 1])\n",
    "        arg2 = ' '.join(src_words[pointers[i][2]:pointers[i][3] + 1])\n",
    "        touplet = (arg1.strip(), eventIdxToName[e], arg2.strip())\n",
    "        if not is_full_match(touplet, touples):\n",
    "            touples.append(touplet)\n",
    "        i += 1\n",
    "    \n",
    "    return touples\n",
    "\n",
    "\n",
    "# In[117]:\n",
    "\n",
    "def get_answer_pointers(arg1start_preds, arg1end_preds, arg2start_preds, arg2end_preds, sent_len):\n",
    "    arg1_prob = -1.0\n",
    "    arg1start = -1\n",
    "    arg1end = -1\n",
    "    max_ent_len = 38#5\n",
    "    max_trig_len = 7#\n",
    "    for i in range(0, sent_len):\n",
    "        for j in range(i, min(sent_len, i + max_trig_len)):#\n",
    "            if arg1start_preds[i] * arg1end_preds[j] > arg1_prob:\n",
    "                arg1_prob = arg1start_preds[i] * arg1end_preds[j]\n",
    "                arg1start = i\n",
    "                arg1end = j\n",
    "\n",
    "    arg2_prob = -1.0\n",
    "    arg2start = -1\n",
    "    arg2end = -1\n",
    "    for i in range(0, arg1start):\n",
    "        for j in range(i, min(arg1start, i + max_ent_len)):#\n",
    "            if arg2start_preds[i] * arg2end_preds[j] > arg2_prob:\n",
    "                arg2_prob = arg2start_preds[i] * arg2end_preds[j]\n",
    "                arg2start = i\n",
    "                arg2end = j\n",
    "    for i in range(arg1end + 1, sent_len):\n",
    "        for j in range(i, min(sent_len, i + max_ent_len)):#\n",
    "            if arg2start_preds[i] * arg2end_preds[j] > arg2_prob:\n",
    "                arg2_prob = arg2start_preds[i] * arg2end_preds[j]\n",
    "                arg2start = i\n",
    "                arg2end = j\n",
    "\n",
    "    arg2_prob1 = -1.0\n",
    "    arg2start1 = -1\n",
    "    arg2end1 = -1\n",
    "    for i in range(0, sent_len):\n",
    "        for j in range(i, min(sent_len, i + max_ent_len)):#\n",
    "            if arg2start_preds[i] * arg2end_preds[j] > arg2_prob1:\n",
    "                arg2_prob1 = arg2start_preds[i] * arg2end_preds[j]\n",
    "                arg2start1 = i\n",
    "                arg2end1 = j\n",
    "\n",
    "    arg1_prob1 = -1.0\n",
    "    arg1start1 = -1\n",
    "    arg1end1 = -1\n",
    "    for i in range(0, arg2start1):\n",
    "        for j in range(i, min(arg2start1, i + max_trig_len)):#\n",
    "            if arg1start_preds[i] * arg1end_preds[j] > arg1_prob1:\n",
    "                arg1_prob1 = arg1start_preds[i] * arg1end_preds[j]\n",
    "                arg1start1 = i\n",
    "                arg1end1 = j\n",
    "    for i in range(arg2end1 + 1, sent_len):\n",
    "        for j in range(i, min(sent_len, i + max_trig_len)):\n",
    "            if arg1start_preds[i] * arg1end_preds[j] > arg1_prob1:\n",
    "                arg1_prob1 = arg1start_preds[i] * arg1end_preds[j]\n",
    "                arg1start1 = i\n",
    "                arg1end1 = j\n",
    "    if arg1_prob * arg2_prob > arg1_prob1 * arg2_prob1:\n",
    "        return arg1start, arg1end, arg2start, arg2end\n",
    "    else:\n",
    "        return arg1start1, arg1end1, arg2start1, arg2end1\n",
    "\n",
    "\n",
    "# In[118]:\n",
    "\n",
    "\n",
    "\n",
    "def get_pred_triples(arg1s, arg1e, arg2s, arg2e, eTypes, src_words):\n",
    "    triples = []\n",
    "    all_triples = []\n",
    "\n",
    "    \n",
    "    for i in range(0, len(eTypes)):\n",
    "       ## r = np.argmax(rel[i][1:]) + 1\n",
    "       ## if r == relnameToIdx['None']:\n",
    "       ##     break\n",
    "        s1, e1, s2, e2 = get_answer_pointers(arg1s[i], arg1e[i], arg2s[i], arg2e[i], len(src_words))\n",
    "        if s1 == 0 or e1 == 0 :\n",
    "            break\n",
    "\n",
    "        ev = np.argmax(eTypes[i][1:]) + 1#event type can not be <pad> or <None>\n",
    "\n",
    "        arg1 = ' '.join(src_words[s1: e1 + 1])\n",
    "        arg2 = ' '.join(src_words[s2: e2 + 1])\n",
    "        arg1 = arg1.strip()\n",
    "        arg2 = arg2.strip()\n",
    "        if arg1 == arg2:\n",
    "            continue\n",
    "\n",
    "        triplet = (arg1, eventIdxToName[ev], arg2)   ###relIdxToName[r]\n",
    "\n",
    "        if (triplet[0], triplet[1], triplet[2]) in [(t[0], t[1],t[2]) for t in triples]:#same (trigger, argument) pair can not have two different role\n",
    "        \tcontinue\n",
    "\n",
    "        all_triples.append(triplet)\n",
    "        if not is_full_match(triplet, triples):\n",
    "            triples.append(triplet)\n",
    "    \n",
    "    return triples, all_triples\n",
    "# In[119]:\n",
    "\n",
    "\n",
    "def get_F1(data, preds):\n",
    "    gt_pos = 0\n",
    "    pred_pos = 0\n",
    "    total_pred_pos = 0\n",
    "    correct_pos = 0\n",
    "    ti=0\n",
    "    tc=0\n",
    "    ai=0\n",
    "    ro=0\n",
    "    for i in range(0, len(data)):\n",
    "        ##[2,45,67,10],[2,5,13,7],[(1,2,6,7),(7,8,10,10),..],[23,33,1,8]\n",
    "        gt_triples = get_gt_triples(data[i].SrcWords,  data[i].TrgPointers, data[i].eventTypes)\n",
    "\n",
    "        pred_triples, all_pred_triples = get_pred_triples(preds[0][i], preds[1][i], preds[2][i], preds[3][i],\n",
    "                                                          preds[4][i], data[i].SrcWords)\n",
    "        total_pred_pos += len(all_pred_triples)\n",
    "        gt_pos += len(gt_triples)\n",
    "        pred_pos += len(pred_triples)\n",
    "        for gt_triple in gt_triples:\n",
    "            if is_full_match(gt_triple, pred_triples):\n",
    "                correct_pos += 1\n",
    "\n",
    "            if gt_triple[0] in [pred[0] for pred in pred_triples]:\n",
    "                ti+=1\n",
    "\n",
    "            if gt_triple[:2] in [pred[:2] for pred in pred_triples]:\n",
    "                tc+=1\n",
    "\n",
    "            ##if gt_triple[1:3] in [pred[1:3] for pred in pred_triples]:\n",
    "            ##    ai+=1\n",
    "##\n",
    "            ##if (gt_triple[1], gt_triple[2], gt_triple[4]) in [(pred[1], pred[2], pred[4]) for pred in pred_triples]:\n",
    "            ##    ro+=1\n",
    "##\n",
    "    #print(total_pred_pos)\n",
    "    return pred_pos, gt_pos, correct_pos, ti, tc, ai, ro\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def write_test_res(data, actual_sent, actual_data, preds, outfile):\n",
    "    writer = open(outfile, 'w')\n",
    "    for i in range(0, len(data)):\n",
    "        writer.write('Sentence= ' + actual_sent[i])\n",
    "        writer.write('\\n')\n",
    "        writer.write('Actual= '+ actual_data[i])\n",
    "        writer.write('\\n')\n",
    "        pred_triples, _ = get_pred_triples(preds[0][i], preds[1][i], preds[2][i], preds[3][i], preds[4][i], data[i].SrcWords)\n",
    "        pred_triples_str = []\n",
    "        for pt in pred_triples:\n",
    "            pred_triples_str.append(pt[0] + ' ; ' + pt[1] + ' ; ' + pt[2] )\n",
    "        writer.write('predicted:  ')\n",
    "        writer.write(' | '.join(pred_triples_str) + '\\n\\n\\n')\n",
    "    writer.close()\n",
    "\n",
    "def load_word_embedding(embed_file, vocab):\n",
    "    '''\n",
    "    vocab: all the uniq words present in the doc\n",
    "    embed_file: pretrained word embedding path\n",
    "    '''\n",
    "    #print('vocab length:', len(vocab))\n",
    "    custom_print('vocab length:', len(vocab))\n",
    "    embed_vocab = OrderedDict()#dictionar containing all the words and word_index\n",
    "    embed_matrix = list()\n",
    "\n",
    "    embed_vocab['<PAD>'] = 0\n",
    "    embed_matrix.append(np.zeros(word_embed_dim, dtype=np.float32))\n",
    "\n",
    "    embed_vocab['<UNK>'] = 1\n",
    "    embed_matrix.append(np.random.uniform(-0.25, 0.25, word_embed_dim))\n",
    "\n",
    "    word_idx = 2\n",
    "    with open(embed_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            if len(parts) < word_embed_dim + 1:\n",
    "                continue\n",
    "            word = parts[0]\n",
    "            if word in vocab and vocab[word] >= word_min_freq:\n",
    "                vec = [np.float32(val) for val in parts[1:]]\n",
    "                embed_matrix.append(vec)\n",
    "                embed_vocab[word] = word_idx\n",
    "                word_idx += 1\n",
    "\n",
    "    for word in vocab:\n",
    "        if word not in embed_vocab and vocab[word] >= word_min_freq:\n",
    "            embed_matrix.append(np.random.uniform(-0.25, 0.25, word_embed_dim))\n",
    "            embed_vocab[word] = word_idx\n",
    "            word_idx += 1\n",
    "\n",
    "    #print('embed dictionary length:', len(embed_vocab))\n",
    "    custom_print('embed dictionary length:', len(embed_vocab))\n",
    "    return embed_vocab, np.array(embed_matrix, dtype=np.float32)\n",
    "\n",
    "def build_vocab(tr_data, dv_data, ts_data, save_vocab, embedding_file):\n",
    "    vocab = OrderedDict()\n",
    "    char_v = OrderedDict()\n",
    "    char_v['<PAD>'] = 0\n",
    "    char_v['<UNK>'] = 1\n",
    "    char_idx = 2\n",
    "    for d in tr_data:\n",
    "        for word in d.SrcWords:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = 1\n",
    "            else:\n",
    "                vocab[word] += 1\n",
    "\n",
    "            for c in word:\n",
    "                if c not in char_v:\n",
    "                    char_v[c] = char_idx\n",
    "                    char_idx += 1\n",
    "\n",
    "    for d in dv_data + ts_data:\n",
    "        for word in d.SrcWords:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = 0\n",
    "\n",
    "            for c in word:\n",
    "                if c not in char_v:\n",
    "                    char_v[c] = char_idx\n",
    "                    char_idx += 1\n",
    "\n",
    "    word_v, embed_matrix = load_word_embedding(embedding_file, vocab)\n",
    "    output = open(save_vocab, 'wb')\n",
    "    pickle.dump([word_v, char_v], output)\n",
    "    output.close()\n",
    "    return word_v, char_v, embed_matrix\n",
    "\n",
    "\n",
    "def build_tags(file1, file2, file3):\n",
    "    lines = open(file1).readlines() + open(file2).readlines() + open(file3).readlines()\n",
    "    pos_vocab = OrderedDict()\n",
    "    pos_vocab['<PAD>'] = 0\n",
    "    pos_vocab['<UNK>'] = 1\n",
    "    k = 2\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        tags = line.split(' ')\n",
    "        for tag in tags:\n",
    "            if tag not in pos_vocab:\n",
    "                pos_vocab[tag] = k\n",
    "                k += 1\n",
    "    return pos_vocab\n",
    "\n",
    "def load_vocab(vocab_file):\n",
    "    with open(vocab_file, 'rb') as f:\n",
    "        embed_vocab, char_vocab = pickle.load(f)\n",
    "    return embed_vocab, char_vocab\n",
    "\n",
    "def get_max_len(sample_batch):\n",
    "    src_max_len = len(sample_batch[0].SrcWords)\n",
    "    for idx in range(1, len(sample_batch)):\n",
    "        if len(sample_batch[idx].SrcWords) > src_max_len:\n",
    "            src_max_len = len(sample_batch[idx].SrcWords)\n",
    "\n",
    "    trg_max_len = len(sample_batch[0].eventTypes)\n",
    "    for idx in range(1, len(sample_batch)):\n",
    "        if len(sample_batch[idx].eventTypes) > trg_max_len:\n",
    "            trg_max_len = len(sample_batch[idx].eventTypes)\n",
    "\n",
    "    return src_max_len, trg_max_len\n",
    "\n",
    "def get_words_index_seq(words, max_len):\n",
    "    toks = ['[CLS]'] + [wd for wd in words] + ['[SEP]'] + ['[PAD]' for i in range(max_len-len(words))]\n",
    "    bert_ids = bert_tokenizer.convert_tokens_to_ids(toks)\n",
    "    bert_mask = [1 for idx in range(len(words) + 2)] + [0 for idx in range(max_len - len(words))]\n",
    "    return bert_ids, bert_mask\n",
    "\n",
    "\n",
    "# In[128]:\n",
    "\n",
    "\n",
    "def get_pos_tag_index_seq(pos_seq, max_len):\n",
    "    seq = list()\n",
    "    for t in pos_seq:\n",
    "        if t in pos_vocab:\n",
    "            seq.append(pos_vocab[t])\n",
    "        else:\n",
    "            seq.append(pos_vocab['<UNK>'])\n",
    "    pad_len = max_len - len(seq)\n",
    "    for i in range(0, pad_len):\n",
    "        seq.append(pos_vocab['<PAD>'])\n",
    "    return seq\n",
    "\n",
    "\n",
    "# In[129]:\n",
    "\n",
    "\n",
    "def get_padded_mask(cur_len, max_len):\n",
    "    mask_seq = list()\n",
    "    for i in range(0, cur_len):\n",
    "        mask_seq.append(0)\n",
    "    pad_len = max_len - cur_len\n",
    "    for i in range(0, pad_len):\n",
    "        mask_seq.append(1)\n",
    "    return mask_seq\n",
    "\n",
    "\n",
    "# In[130]:\n",
    "\n",
    "\n",
    "def get_char_seq(words, max_len):\n",
    "    char_seq = list()\n",
    "    for i in range(0, conv_filter_size - 1):\n",
    "        char_seq.append(char_vocab['<PAD>'])\n",
    "    for word in words:\n",
    "        for c in word[0:min(len(word), max_word_len)]:\n",
    "            if c in char_vocab:\n",
    "                char_seq.append(char_vocab[c])\n",
    "            else:\n",
    "                char_seq.append(char_vocab['<UNK>'])\n",
    "        pad_len = max_word_len - len(word)\n",
    "        for i in range(0, pad_len):\n",
    "            char_seq.append(char_vocab['<PAD>'])\n",
    "        for i in range(0, conv_filter_size - 1):\n",
    "            char_seq.append(char_vocab['<PAD>'])\n",
    "\n",
    "    pad_len = max_len - len(words)\n",
    "    for i in range(0, pad_len):\n",
    "        for i in range(0, max_word_len + conv_filter_size - 1):\n",
    "            char_seq.append(char_vocab['<PAD>'])\n",
    "    return char_seq\n",
    "\n",
    "\n",
    "# In[131]:\n",
    "\n",
    "\n",
    "#[1,7,3,10,-1,-1,-1,...]\n",
    "def get_padded_pointers_trig(pointers, pidx, max_len):\n",
    "    idx_list = []\n",
    "    for p in pointers:\n",
    "        idx_list.append(p[pidx])\n",
    "    idx_list.append(0)\n",
    "    pad_len = max_len - len(pointers)\n",
    "    for i in range(0, pad_len):\n",
    "        idx_list.append(-1)\n",
    "    return idx_list\n",
    "\n",
    "\n",
    "\n",
    "#[1,7,3,10,-1,-1,-1,...]\n",
    "def get_padded_pointers_arg(pointers, pidx, max_len):\n",
    "    idx_list = []\n",
    "    for p in pointers:\n",
    "        idx_list.append(p[pidx])\n",
    "    idx_list.append(1)\n",
    "    pad_len = max_len - len(pointers)\n",
    "    for i in range(0, pad_len):\n",
    "        idx_list.append(-1)\n",
    "    return idx_list\n",
    "\n",
    "\n",
    "# In[132]:\n",
    "\n",
    "\n",
    "#[1,2,3,4,0,0,0,...]\n",
    "def get_positional_index(sent_len, max_len):\n",
    "    index_seq = [min(i + 1, max_positional_idx - 1) for i in range(sent_len)]\n",
    "    index_seq += [0 for i in range(max_len - sent_len)]\n",
    "    return index_seq\n",
    "\n",
    "\n",
    "# In[133]:\n",
    "\n",
    "\n",
    "#[5,2,19,23,'None',<pad>,<pad>,<pad>,...]\n",
    "def get_padded_relations(rels, max_len):\n",
    "    rel_list = []\n",
    "    for r in rels:\n",
    "        rel_list.append(r)\n",
    "    rel_list.append(relnameToIdx['NA'])\n",
    "    pad_len = max_len + 1 - len(rel_list)\n",
    "    for i in range(0, pad_len):\n",
    "        rel_list.append(relnameToIdx['<PAD>'])\n",
    "    return rel_list\n",
    "\n",
    "\n",
    "# In[134]:\n",
    "\n",
    "\n",
    "#[5,2,19,23,'None',<pad>,<pad>,<pad>,...]\n",
    "def get_padded_events(events, max_len):\n",
    "    event_list = []\n",
    "    for r in events:\n",
    "        event_list.append(r)\n",
    "    #event_list.append(eventnameToIdx['None'])\n",
    "    pad_len = max_len + 1 - len(event_list)\n",
    "    for i in range(0, pad_len):\n",
    "        event_list.append(eventnameToIdx['<PAD>'])\n",
    "    return event_list\n",
    "\n",
    "\n",
    "# In[135]:\n",
    "\n",
    "\n",
    "#[5,2,19,23,'None',<pad>,<pad>,<pad>,...]\n",
    "def get_padded_args(args, max_len):\n",
    "    arg_list = []\n",
    "    for r in args:\n",
    "        arg_list.append(r)\n",
    "    arg_list.append(argnameToIdx['NA'])\n",
    "    pad_len = max_len + 1 - len(arg_list)\n",
    "    for i in range(0, pad_len):\n",
    "        arg_list.append(argnameToIdx['<PAD>'])\n",
    "    return arg_list\n",
    "\n",
    "\n",
    "# In[136]:\n",
    "\n",
    "\n",
    "#[5,2,19,23,'None',<pad>,<pad>,<pad>,...]\n",
    "def get_relation_index_seq(rel_ids, max_len):\n",
    "    seq = list()\n",
    "    # seq.append(relnameToIdx['<SOS>'])\n",
    "    for r in rel_ids:\n",
    "        seq.append(r)\n",
    "    seq.append(relnameToIdx['NA'])\n",
    "    pad_len = max_len + 1 - len(seq)\n",
    "    for i in range(0, pad_len):\n",
    "        seq.append(relnameToIdx['<PAD>'])\n",
    "    return seq\n",
    "\n",
    "\n",
    "# In[137]:\n",
    "\n",
    "\n",
    "def get_entity_masks(pointers, src_max, trg_max):\n",
    "    arg1_masks = []#\n",
    "    arg2_masks = []#\n",
    "    for p in pointers:#for each record in a sentence\n",
    "        arg1_mask = [1 for i in range(src_max)]#list of size max_src_len [1, 1, 1, 1,...]\n",
    "        arg1_mask[p[0]] = 0#set the value of word_pos_index of the first word of entity_1=0 [1, 1, 1, 0, 1, 1,...]\n",
    "        arg1_mask[p[1]] = 0#set the value of word_pos_index of the last word of entity_1=0 [1, 1, 1, 0, 1, 1, 0, 1, 1,...]\n",
    "\n",
    "        arg2_mask = [1 for i in range(src_max)]#list of size max_src_len [1, 1, 1,...]\n",
    "        arg2_mask[p[2]] = 0#set the value of word_pos_index of the first word of entity_1=0\n",
    "        arg2_mask[p[3]] = 0#set the value of word_pos_index of the last word of entity_2=0\n",
    "\n",
    "        arg1_masks.append(arg1_mask)\n",
    "        arg2_masks.append(arg2_mask)\n",
    "\n",
    "    pad_len = trg_max + 1 -len(pointers)\n",
    "    for i in range(0, pad_len):\n",
    "        arg1_mask = [1 for i in range(src_max)]\n",
    "        arg2_mask = [1 for i in range(src_max)]\n",
    "        arg1_masks.append(arg1_mask)\n",
    "        arg2_masks.append(arg2_mask)\n",
    "    return arg1_masks, arg2_masks #list of length max_trg_len where each item is list of size max_src_len. Each item of that list is mask where all but start and end index of entity_1 and entity_2 set to 1 respectively.\n",
    "\n",
    "\n",
    "# In[138]:\n",
    "\n",
    "\n",
    "def get_batch_data(cur_samples, is_training=False):\n",
    "    \"\"\"\n",
    "    Returns the training samples and labels as numpy array\n",
    "    \"\"\"\n",
    "    batch_src_max_len, batch_trg_max_len = get_max_len(cur_samples)#call get_max_len(): find the max length of src and target per batch\n",
    "    batch_trg_max_len += 1#may be EOS relation\n",
    "    #print('max_src_len_batch={}'.format(batch_src_max_len))\n",
    "    #print('max_trg_len_batch={}'.format(batch_trg_max_len))\n",
    "    src_words_list = list()#each element is a list of word indices present in a sentence\n",
    "    bert_mask_list = list()\n",
    "    src_words_mask_list = list()#each element is a list of mask value, 0 if actual word and 1 if padded word\n",
    "    src_char_seq = list()#each element is a charater idex sequence per sentence\n",
    "    decoder_input_list = list()\n",
    "    #adj_lst = []\n",
    "    positional_index_list = []#each element is a sequence of positional index of the words in a sentence\n",
    "    src_pos_tag_seq = list()\n",
    "\n",
    "    rel_seq = list()\n",
    "    event_seq=list()#******\n",
    "    arg_seq=list()#********\n",
    "    trigger_start_seq = list()\n",
    "    trigger_end_seq = list()\n",
    "    entity_start_seq = list()\n",
    "    entity_end_seq = list()\n",
    "    trigger_mask_seq = []\n",
    "    entity_mask_seq = []\n",
    "    '''all commmnets in the following are about the 'items' appended to that respective lists'''\n",
    "    for sample in cur_samples:\n",
    "        bert_ids, bert_mask = get_words_index_seq(sample.SrcWords, batch_src_max_len)\n",
    "        src_words_list.append(bert_ids)#call get_words_index_seq():[list of word_index of length max_src_len]\n",
    "        bert_mask_list.append(bert_mask)\n",
    "        src_words_mask_list.append(get_padded_mask(sample.SrcLen, batch_src_max_len))#call get_padded_mask(): [0,0,0..till srclength,1,1,1,...till padded length]\n",
    "        src_char_seq.append(get_char_seq(sample.SrcWords, batch_src_max_len))#call get_char_seq(): [character index sequence with padded for CNN processing]\n",
    "        #cur_masked_adj = np.zeros((batch_src_max_len, batch_src_max_len), dtype=np.float32)#skip\n",
    "        #cur_masked_adj[:len(sample.SrcWords), :len(sample.SrcWords)] = sample.AdjMat#skip\n",
    "        #adj_lst.append(cur_masked_adj)#skip\n",
    "        positional_index_list.append(get_positional_index(len(sample.SrcWords), batch_src_max_len))#positional index of each word in the source sentence padded with 0\n",
    "        #src_pos_tag_seq.append(get_pos_tag_index_seq(sample.PosTags, batch_src_max_len))#each element is [list of tag index of each word in the sentence of length max_src_len]\n",
    "\n",
    "        if is_training:\n",
    "            trigger_start_seq.append(get_padded_pointers_trig(sample.TrgPointers, 0, batch_trg_max_len))#list of all the start index of the tuple's event in a sentence with padding -1 (to max_trg_len)\n",
    "            trigger_end_seq.append(get_padded_pointers_trig(sample.TrgPointers, 1, batch_trg_max_len))#list of all the end index of the tuple's event in a sentence with pad -1 (to max_trg_len)\n",
    "            entity_start_seq.append(get_padded_pointers_arg(sample.TrgPointers, 2, batch_trg_max_len))#list of all the first index of the tuple's argument in a sequence with pad -1(to max_trg_len)\n",
    "            entity_end_seq.append(get_padded_pointers_arg(sample.TrgPointers, 3, batch_trg_max_len))#list of all the end index of the tuple's argument in a sentence with pad -1(to max_trg_len)\n",
    "            #rel_seq.append(get_padded_relations(sample.TrgRels, batch_trg_max_len))#list of all the relation index(from rel_vocab) padded with 'NA' and '<Pad>'\n",
    "\n",
    "            event_seq.append(get_padded_events(sample.eventTypes, batch_trg_max_len))#list of all the event index(from event_vocab) padded with <Pad>'\n",
    "           # arg_seq.append(get_padded_args(sample.argTypes, batch_trg_max_len))#list of all the event index(from event_vocab) padded with 'NA' and '<Pad>'\n",
    "\n",
    "            #decoder_input_list.append(get_relation_index_seq(sample.TrgRels, batch_trg_max_len))#list of all the relation index(from rel_vocab) padded with 'None' and '<Pad>'\n",
    "\n",
    "            trigger_mask, entity_mask = get_entity_masks(sample.TrgPointers, batch_src_max_len, batch_trg_max_len)#list of length max_trg_len where each item is a list of size max_src_len. Each item of that list is mask where all but start and end index of entity_1 (and entity_2) set to 1 (respectively).\n",
    "            trigger_mask_seq.append(trigger_mask)\n",
    "            entity_mask_seq.append(entity_mask)\n",
    "        #else:\n",
    "            #decoder_input_list.append(get_relation_index_seq([], 1))\n",
    "\n",
    "    return {'src_words': np.array(src_words_list, dtype=np.float32),#list of word_index\n",
    "            'bert_mask': np.array(bert_mask_list),\n",
    "            'pos_tag_seq': np.array(src_pos_tag_seq),#list of pos tag index\n",
    "            'positional_seq': np.array(positional_index_list),#list of word_position_index\n",
    "            'src_words_mask': np.array(src_words_mask_list),#list of source word masks [0,0,0,1,1]\n",
    "            'src_chars': np.array(src_char_seq),#list of source character sequences with padding for CNN operation\n",
    "           # 'decoder_input': np.array(decoder_input_list),#list of all the relation indexes present in the trg_seq padded till amx_trg_len(for training), [] for testing\n",
    "            'event': np.array(event_seq),\n",
    "           # 'arg': np.array(arg_seq),\n",
    "            ##'rel': np.array(rel_seq),#list of relation seq padded till max_trg_len\n",
    "            'trigger_start':np.array(trigger_start_seq),#list of all the start index of the first entities (present in the trg_seq of len max_trg_len) padded with -1\n",
    "            'trigger_end': np.array(trigger_end_seq),#list of all the last index of the first entities (present in the trg_seq of len max_trg_len) padded with -1\n",
    "            'entity_start': np.array(entity_start_seq),#list of all the start index of the second entities (present in the trg_seq of len max_trg_len) padded with -1\n",
    "            'entity_end': np.array(entity_end_seq),#list of all the last index of the second entities (present in the trg_seq of len max_trg_len) padded with -1\n",
    "            'trigger_mask': np.array(trigger_mask_seq),#list of entity_1 mask, it's a list of size max_trg_len. and each item  is a list of size max_src_len, alll 1 but the entity_1's start and end pos is 0.\n",
    "            'entity_mask': np.array(entity_mask_seq)}#list of entity_2 mask,...\n",
    " \n",
    "\n",
    "class WordEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, pre_trained_embed_matrix, drop_out_rate):\n",
    "        super(WordEmbeddings, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(pre_trained_embed_matrix))\n",
    "        self.dropout = nn.Dropout(drop_out_rate)\n",
    "\n",
    "    def forward(self, words_seq):\n",
    "        word_embeds = self.embeddings(words_seq)\n",
    "        word_embeds = self.dropout(word_embeds)\n",
    "        return word_embeds\n",
    "\n",
    "    def weight(self):\n",
    "        return self.embeddings.weight\n",
    "\n",
    "\n",
    "# In[140]:\n",
    "\n",
    "\n",
    "class CharEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, drop_out_rate):\n",
    "        super(CharEmbeddings, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(drop_out_rate)\n",
    "\n",
    "    def forward(self, words_seq):\n",
    "        char_embeds = self.embeddings(words_seq)\n",
    "        char_embeds = self.dropout(char_embeds)\n",
    "        return char_embeds\n",
    "\n",
    "\n",
    "# In[141]:\n",
    "\n",
    "\n",
    "class POSEmbeddings(nn.Module):\n",
    "    def __init__(self, tag_len, tag_dim, drop_out_rate):\n",
    "        super(POSEmbeddings, self).__init__()\n",
    "        self.embeddings = nn.Embedding(tag_len, tag_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(drop_out_rate)\n",
    "\n",
    "    def forward(self, pos_seq):\n",
    "        pos_embeds = self.embeddings(pos_seq)\n",
    "        pos_embeds = self.dropout(pos_embeds)\n",
    "        return pos_embeds\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_dim = input_dim#300\n",
    "        self.linear_ctx = nn.Linear(self.input_dim, self.input_dim, bias=False)\n",
    "        self.linear_query = nn.Linear(self.input_dim, self.input_dim, bias=True)\n",
    "        self.v = nn.Linear(self.input_dim, 1)\n",
    "\n",
    "    def forward(self, s_prev, enc_hs, src_mask):\n",
    "        uh = self.linear_ctx(enc_hs)\n",
    "        wq = self.linear_query(s_prev)\n",
    "        wquh = torch.tanh(wq + uh)\n",
    "        attn_weights = self.v(wquh).squeeze()\n",
    "        attn_weights.data.masked_fill_(src_mask.data, -float('inf'))\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        ctx = torch.bmm(attn_weights.unsqueeze(1), enc_hs).squeeze()\n",
    "        return ctx, attn_weights\n",
    "\n",
    "\n",
    "# In[143]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BERT(nn.Module):\n",
    "    def __init__(self, drop_out_rate):\n",
    "        super(BERT, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        if not update_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.dropout = nn.Dropout(drop_out_rate)\n",
    "\n",
    "    def forward(self, input_ids, bert_mask, is_training=False):\n",
    "        seq_out = self.bert(input_ids, attention_mask=bert_mask)\n",
    "        seq_out = seq_out[0][:, 1:-1, :]\n",
    "        # seq_out = self.dropout(seq_out)\n",
    "        return seq_out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layers, is_bidirectional, drop_out_rate):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim#768+char_emb+pos_emb\n",
    "        self.hidden_dim = hidden_dim#150\n",
    "        self.layers = layers#1\n",
    "        self.is_bidirectional = is_bidirectional#True\n",
    "        self.drop_rate = drop_out_rate#0.3\n",
    "        self.bert_vec = BERT(drop_out_rate)\n",
    "        #self.word_embeddings = WordEmbeddings(len(word_vocab), word_embed_dim, word_embed_matrix, drop_rate)\n",
    "        ##self.pos_embeddings = POSEmbeddings(len(pos_vocab), pos_embed_dim, drop_rate)\n",
    "        self.char_embeddings = CharEmbeddings(len(char_vocab), char_embed_dim, drop_rate)\n",
    "        # self.pos_embeddings = nn.Embedding(max_positional_idx, positional_embed_dim, padding_idx=0)\n",
    "        if enc_type == 'LSTM':\n",
    "            self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.layers, batch_first=True,\n",
    "                                bidirectional=self.is_bidirectional, dropout=drop_out_rate)\n",
    "        '''\n",
    "        elif enc_type == 'GCN':\n",
    "            self.reduce_dim = nn.Linear(self.input_dim, 2 * self.hidden_dim)\n",
    "            self.gcn = GCN(gcn_num_layers, 2* self.hidden_dim, 2 * self.hidden_dim)\n",
    "\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.layers, batch_first=True,\n",
    "                                bidirectional=self.is_bidirectional)\n",
    "            self.gcn = GCN(gcn_num_layers, 2 * self.hidden_dim, 2 * self.hidden_dim)\n",
    "        '''\n",
    "\n",
    "        self.dropout = nn.Dropout(self.drop_rate)\n",
    "        self.conv1d = nn.Conv1d(char_embed_dim, char_feature_size, conv_filter_size)\n",
    "        self.max_pool = nn.MaxPool1d(max_word_len + conv_filter_size - 1, max_word_len + conv_filter_size - 1)\n",
    "        # self.mhc = 3\n",
    "        # self.mha = Multi_Head_Self_Attention(self.mhc, 2 * self.hidden_dim)\n",
    "\n",
    "    def forward(self, words, bert_mask,  chars, pos_seq, is_training=False):   ##pos_tag_seq,\n",
    "        bert_embeds = self.bert_vec(words, bert_mask, is_training)\n",
    "        word_input = bert_embeds\n",
    "        #src_word_embeds = self.word_embeddings(words)#[bs, max_seq_len, emb_dim]\n",
    "        #custom_print(word_input.shape)\n",
    "       ### pos_embeds = self.pos_embeddings(pos_tag_seq)\n",
    "        #custom_print(pos_embeds.shape)\n",
    "        # pos_embeds = self.dropout(self.pos_embeddings(pos_seq))\n",
    "        char_embeds = self.char_embeddings(chars)#[]\n",
    "        char_embeds = char_embeds.permute(0, 2, 1)#[bs, emb_dim, max_seq_len]\n",
    "\n",
    "        char_feature = torch.tanh(self.max_pool(self.conv1d(char_embeds)))\n",
    "        char_feature = char_feature.permute(0, 2, 1)\n",
    "        #custom_print(char_feature.shape)\n",
    "\n",
    "        words_input = torch.cat((word_input, char_feature), -1)#[bs, max_seq_len, emb_dim=350]\n",
    "        #custom_print(words_input.shape)\n",
    "\n",
    "        if enc_type == 'LSTM':\n",
    "            outputs, hc = self.lstm(words_input)\n",
    "        '''\n",
    "        elif enc_type == 'GCN':\n",
    "            outputs = self.reduce_dim(words_input)\n",
    "            outputs = self.gcn(outputs, adj)\n",
    "        else:\n",
    "            outputs, hc = self.lstm(words_input)\n",
    "            outputs = self.dropout(outputs)\n",
    "            outputs = self.gcn(outputs, adj)\n",
    "        '''\n",
    "        # outputs += pos_embeds\n",
    "        # outputs = self.mha(outputs, outputs, outputs)\n",
    "        outputs = self.dropout(outputs)#(bs, seq_len, hid_dim)\n",
    "        #custom_print(outputs.shape)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim=300, hidden_dim=300, layers=1, drop_out_rate=0.3, max_length=23):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "        self.drop_rate = drop_out_rate\n",
    "        self.max_length = max_length\n",
    "\n",
    "        if att_type == 0:\n",
    "            self.attention = Attention(input_dim)\n",
    "            self.lstm = nn.LSTMCell(10 * self.input_dim, self.hidden_dim)\n",
    "        elif att_type == 1:\n",
    "            # self.w = nn.Linear(9 * self.input_dim, self.input_dim)\n",
    "            self.attention = Attention(input_dim)\n",
    "            self.lstm = nn.LSTMCell(10 * self.input_dim, self.hidden_dim)\n",
    "        else:\n",
    "            # self.w = nn.Linear(9 * self.input_dim, self.input_dim)\n",
    "            self.attention1 = Attention(input_dim)\n",
    "            self.attention2 = Attention(input_dim)\n",
    "            self.lstm = nn.LSTMCell(10 * self.input_dim, self.hidden_dim)\n",
    "\n",
    "        self.trig_pointer_lstm = nn.LSTM(2 * self.input_dim, self.input_dim, 1, batch_first=True,\n",
    "                                       bidirectional=True)\n",
    "        self.ent_pointer_lstm = nn.LSTM(4 * self.input_dim, self.input_dim, 1, batch_first=True,\n",
    "                                       bidirectional=True)\n",
    "\n",
    "        #self.arg1s_lin = nn.Linear(2 * self.input_dim, 1)#trigger_s\n",
    "        self.trigger_s_lin = nn.Linear(2 * self.input_dim, 1)\n",
    "        #self.arg1e_lin = nn.Linear(2 * self.input_dim, 1)#trigger_e\n",
    "        self.trigger_e_lin = nn.Linear(2 * self.input_dim, 1)\n",
    "        #self.arg2s_lin = nn.Linear(2 * self.input_dim, 1)#entity_s\n",
    "        self.entity_s_lin = nn.Linear(2 * self.input_dim, 1)\n",
    "        #self.arg2e_lin = nn.Linear(2 * self.input_dim, 1)#entity_e\n",
    "        self.entity_e_lin = nn.Linear(2 * self.input_dim, 1)\n",
    "\n",
    "\n",
    "        self.et_lin = nn.Linear(5* self.input_dim, len(eventnameToIdx))#***************to identify the event type\n",
    "        ##self.argt_lin = nn.Linear(9* self.input_dim, len(argnameToIdx))#***************to identify the argumwnt type\n",
    "\n",
    "        ##self.rel_lin = nn.Linear(9 * self.input_dim, len(relnameToIdx))#to identify the role\n",
    "\n",
    "        self.dropout = nn.Dropout(self.drop_rate)\n",
    "        self.w = nn.Linear(8 * self.input_dim, self.input_dim)\n",
    "\n",
    "    def forward(self, prev_tuples, h_prev, enc_hs, src_mask, trigger, entity, trigger_mask, entity_mask,is_training=False):\n",
    "\n",
    "        src_time_steps = enc_hs.size()[1]\n",
    "\n",
    "        if att_type == 0:#not used\n",
    "            ctx, attn_weights = self.attention(h_prev[0].squeeze().unsqueeze(1).repeat(1, src_time_steps, 1),\n",
    "                                                enc_hs, src_mask)\n",
    "        elif att_type == 1:#not used\n",
    "            print(\" yes {}\".format(prev_tuples.size()))\n",
    "            reduce_prev_tuples = self.w(prev_tuples)\n",
    "            ctx, attn_weights = self.attention(reduce_prev_tuples.unsqueeze(1).repeat(1, src_time_steps, 1),\n",
    "                                                enc_hs, src_mask)\n",
    "        else:\n",
    "            ctx1, attn_weights1 = self.attention1(h_prev[0].squeeze().unsqueeze(1).repeat(1, src_time_steps, 1),\n",
    "                                               enc_hs, src_mask)\n",
    "            print(\" yes {}\".format(prev_tuples.size()))\n",
    "            reduce_prev_tuples = self.w(prev_tuples)\n",
    "            ctx2, attn_weights2 = self.attention2(reduce_prev_tuples.unsqueeze(1).repeat(1, src_time_steps, 1),\n",
    "                                               enc_hs, src_mask)\n",
    "            ctx = torch.cat((ctx1, ctx2), -1)#[bs,2*300]\n",
    "            attn_weights = (attn_weights1 + attn_weights2) / 2#[bs,src_seq_len]\n",
    "\n",
    "        s_cur = torch.cat((prev_tuples, ctx), 1)#[bs, 11*300]\n",
    "        hidden, cell_state = self.lstm(s_cur, h_prev)\n",
    "        hidden = self.dropout(hidden)#[bs, 300]\n",
    "\n",
    "        if use_hadamard:\n",
    "            enc_hs = enc_hs * attn_weights.unsqueeze(2)\n",
    "\n",
    "        trig_pointer_lstm_input = torch.cat((enc_hs, hidden.unsqueeze(1).repeat(1, src_time_steps, 1)), 2)#[bs, src_seq_len, 2*300]\n",
    "        trig_pointer_lstm_out, phc = self.trig_pointer_lstm(trig_pointer_lstm_input)\n",
    "        trig_pointer_lstm_out = self.dropout(trig_pointer_lstm_out)#[bs, src_seq_len, 2*300]\n",
    "\n",
    "        ent_pointer_lstm_input = torch.cat((trig_pointer_lstm_input, trig_pointer_lstm_out), 2)#[bs,src_seq_len, 4*300]\n",
    "        ent_pointer_lstm_out, phc = self.ent_pointer_lstm(ent_pointer_lstm_input)#\n",
    "        ent_pointer_lstm_out = self.dropout(ent_pointer_lstm_out)#[bs, src_seq_len, 2*300]\n",
    "\n",
    "        trig_s = self.trigger_s_lin(trig_pointer_lstm_out).squeeze()#[bs,src_seq_len]\n",
    "        trig_s.data.masked_fill_(src_mask.data, -float('inf'))\n",
    "\n",
    "        trig_e = self.trigger_e_lin(trig_pointer_lstm_out).squeeze()#[bs,src_seq_len]\n",
    "        trig_e.data.masked_fill_(src_mask.data, -float('inf'))\n",
    "\n",
    "        ent_s = self.entity_s_lin(ent_pointer_lstm_out).squeeze()#[bs,src_seq_len]\n",
    "        ent_s.data.masked_fill_(src_mask.data, -float('inf'))\n",
    "\n",
    "        ent_e = self.entity_e_lin(ent_pointer_lstm_out).squeeze()\n",
    "        ent_e.data.masked_fill_(src_mask.data, -float('inf'))#[bs,src_seq_len]\n",
    "\n",
    "        trig_s_weights = F.softmax(trig_s, dim=-1)#normaized probability of each word index to be the strat index of arg1\n",
    "        trig_e_weights = F.softmax(trig_e, dim=-1)#normaized probability of each word index to be the end index of arg1\n",
    "\n",
    "        trig_sv = torch.bmm(trig_e_weights.unsqueeze(1), trig_pointer_lstm_out).squeeze()#[bs,2*300]\n",
    "        trig_ev = torch.bmm(trig_s_weights.unsqueeze(1), trig_pointer_lstm_out).squeeze()#[bs, 2*300]\n",
    "        trig_et = self.dropout(torch.cat((trig_sv, trig_ev), -1))#[bs,4*300]#holds trigger and event type representation\n",
    "\n",
    "        ent_s_weights = F.softmax(ent_s, dim=-1)\n",
    "        ent_e_weights = F.softmax(ent_e, dim=-1)\n",
    "\n",
    "        ent_sv = torch.bmm(ent_e_weights.unsqueeze(1), ent_pointer_lstm_out).squeeze()#[bs, 2*300]\n",
    "        ent_ev = torch.bmm(ent_s_weights.unsqueeze(1), ent_pointer_lstm_out).squeeze()#[bs, 2*300]\n",
    "        ent_argt = self.dropout(torch.cat((ent_sv, ent_ev), -1))#[bs,4*300]\n",
    "        \n",
    "\n",
    "        event_types = self.et_lin(torch.cat((trig_et,  hidden),-1))   #[bs, 6*300]\n",
    "\n",
    "        #event_types = self.et_lin(torch.cat((trig_et, ent_argt, hidden),-1))#[bs, 9*300]--->[bs, 33]\n",
    "        #custom_print('event_types size={}'.format(event_types.shape))\n",
    "        #arg_types = self.argt_lin(torch.cat((ent_argt, trig_et, hidden), -1))#[bs, 9*300]----> [bs, 7]\n",
    "        #custom_print('arg_types size={}'.format(arg_types.shape))\n",
    "        #rel = self.rel_lin(torch.cat((hidden, trig_et, ent_argt), -1))#[bs,9*300]---->[bs, 36]\n",
    "        #custom_print('rel size={}'.format(rel.shape))\n",
    "\n",
    "        if is_training:\n",
    "            trig_s = F.log_softmax(trig_s, dim=-1)#[bs,max_src_len]\n",
    "            trig_e = F.log_softmax(trig_e, dim=-1)#[bs,max_src_len]\n",
    "            ent_s = F.log_softmax(ent_s, dim=-1)#[bs,max_src_len]\n",
    "            ent_e = F.log_softmax(ent_e, dim=-1)#[bs,max_src_len]\n",
    "            #rel = F.log_softmax(rel, dim=-1)#[bs,max_rel_types]\n",
    "            event_types=F.log_softmax(event_types, dim=-1)#[bs, no_event_types]\n",
    "            #arg_types=F.log_softmax(arg_types, dim=-1)#[bs, no_arg_types]\n",
    "\n",
    "            return _,trig_s.unsqueeze(1), trig_e.unsqueeze(1), ent_s.unsqueeze(1),  ent_e.unsqueeze(1), (hidden, cell_state), trig_et, ent_argt, event_types.unsqueeze(1), _\n",
    "        else:\n",
    "            trig_s = F.softmax(trig_s, dim=-1)\n",
    "            trig_e = F.softmax(trig_e, dim=-1)\n",
    "            ent_s = F.softmax(ent_s, dim=-1)\n",
    "            ent_e = F.softmax(ent_e, dim=-1)\n",
    "            #rel = F.softmax(rel, dim=-1)\n",
    "            event_types=F.log_softmax(event_types, dim=-1)#[bs, no_event_types]\n",
    "            #arg_types=F.log_softmax(arg_types, dim=-1)#[bs, no_arg_types]\n",
    "            return  _,trig_s.unsqueeze(1), trig_e.unsqueeze(1), ent_s.unsqueeze(1), ent_e.unsqueeze(1), (hidden, cell_state), trig_et, ent_argt, event_types.unsqueeze(1), _\n",
    "\n",
    "\n",
    "def get_model(model_id):\n",
    "    if model_id == 1:\n",
    "        return Seq2SeqModel()\n",
    "\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        self.encoder = Encoder(enc_inp_size, int(enc_hidden_size/2), 1, True, drop_rate)\n",
    "        self.decoder = Decoder(dec_inp_size, dec_hidden_size, 1, drop_rate, max_trg_len)\n",
    "      ##  self.relation_embeddings = nn.Embedding(len(relnameToIdx), word_embed_dim)\n",
    "        # self.w = nn.Linear(10 * dec_inp_size, dec_inp_size)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, src_words_seq, bert_mask, src_mask, src_char_seq, pos_seq,  trg_rel_cnt,\n",
    "                trigger_mask, entity_mask, is_training=False):\n",
    "        #custom_print('src_word_seq = {}'.format(src_words_seq.shape))#[32, max_seq_len]\n",
    "        #if is_training:\n",
    "          \n",
    "            #trg_word_embeds = self.dropout(self.relation_embeddings(trg_words_seq))\n",
    "        #custom_print('src_word_seq = {}'.format(src_words_seq.shape))#[32, max_seq_len]\n",
    "        batch_len = src_words_seq.size()[0]#batch_size\n",
    "        #custom_print('batch_size={}'.format(batch_len))\n",
    "        #src_time_steps = src_words_seq.size()[1]#max_src_len in that batch\n",
    "        #custom_print('max_src_len={}'.format(src_time_steps))\n",
    "        time_steps = trg_rel_cnt#max_trg_len (max no of relations present in trg_seq in that batch)\n",
    "        print(time_steps)\n",
    "        #custom_print('time_step={}'.format(time_steps))\n",
    "        #print(src_words_seq.shape)\n",
    "\n",
    "        enc_hs = self.encoder(src_words_seq, bert_mask,src_char_seq, pos_seq, is_training)#call encoder(): (bs, seq_len, hid_dim)    pos_tag_seq, \n",
    "        #custom_print(enc_hs.shape)\n",
    "        src_time_steps = enc_hs.shape[1]\n",
    "        #custom_print('max_src_len={}'.format(src_time_steps))\n",
    "        #custom_print('encoder output dim = {}'.format(enc_hs.shape))\n",
    "        #custom_print('source_mask={}'.format(src_mask.shape))\n",
    "        h0 = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, dec_hidden_size))).cuda()#[bs, 300]\n",
    "        c0 = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, dec_hidden_size))).cuda()#[bs, 300]\n",
    "        dec_hid = (h0, c0)\n",
    "\n",
    "        #dec_inp = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, dec_hidden_size))).cuda()#[bs, 300]\n",
    "        trigger = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, 4 * dec_hidden_size))).cuda()#[bs, 4*300]\n",
    "        entity = autograd.Variable(torch.FloatTensor(torch.zeros(batch_len, 4 * dec_hidden_size))).cuda()#[bs, 4*300]\n",
    "\n",
    "        prev_tuples = torch.cat((trigger, entity), -1)#[bs, 9*300]  , dec_inp\n",
    "        #custom_print('start decoding.....')\n",
    "        if is_training:\n",
    "            dec_outs = self.decoder(prev_tuples, dec_hid, enc_hs, src_mask, trigger, entity,\n",
    "                                    trigger_mask[:, 0, :].squeeze(), entity_mask[:, 0, :].squeeze(), is_training)\n",
    "        else:\n",
    "            dec_outs = self.decoder( prev_tuples, dec_hid, enc_hs, src_mask, trigger, entity, None, None,is_training)\n",
    "            \n",
    "        print(dec_outs[0])    \n",
    "        #rel = dec_outs[0]#[bs,1,no_of_rel_types]\n",
    "        trig_s = dec_outs[1]#[bs, 1, max_src_len]\n",
    "        trig_e = dec_outs[2]#[bs, 1, max_src_len]\n",
    "        ent_s = dec_outs[3]#[bs, 1, max_src_len]\n",
    "        ent_e = dec_outs[4]#[bs, 1, max_src_len]\n",
    "        dec_hid = dec_outs[5]#([bs, hid_dim],[bs, hid_dim])\n",
    "        trigger = dec_outs[6]#[bs, 4*300]\n",
    "        entity = dec_outs[7]#[bs, 4*300]\n",
    "        trg_type=dec_outs[8]#[bs, 1, no_eventTypes]\n",
    "        #arg_type=dec_outs[9]#[bs, 1, no_argTypes]\n",
    "\n",
    "        #topv, topi = rel[:, :, 1:].topk(1)#\n",
    "        #topi = torch.add(topi, 1)\n",
    "        #custom_print('decoding continue...')\n",
    "        for t in range(1, time_steps):\n",
    "            #custom_print('time step: {}'.format(t))\n",
    "            if is_training:\n",
    "                #dec_inp = trg_word_embeds[:, t - 1, :].squeeze()#[bs, 300]\n",
    "                prev_tuples = torch.cat((trigger, entity), -1) + prev_tuples#[bs, 9*300] , dec_inp\n",
    "                dec_outs = self.decoder(prev_tuples, dec_hid, enc_hs, src_mask, trigger, entity,trigger_mask[:, t, :].squeeze(), entity_mask[:, t, :].squeeze(), is_training)\n",
    "            else:\n",
    "                #dec_inp = self.relation_embeddings(topi.squeeze().detach()).squeeze()\n",
    "                prev_tuples = torch.cat((trigger, entity), -1) + prev_tuples\n",
    "                dec_outs = self.decoder( prev_tuples, dec_hid, enc_hs, src_mask, trigger, entity, None, None,\n",
    "                                        is_training) \n",
    "\n",
    "            #cur_rel = dec_outs[0]\n",
    "            cur_trig_s = dec_outs[1]\n",
    "            cur_trig_e = dec_outs[2]\n",
    "            cur_ent_s = dec_outs[3]\n",
    "            cur_ent_e = dec_outs[4]\n",
    "            dec_hid = dec_outs[5]\n",
    "            trigger = dec_outs[6]\n",
    "            entity = dec_outs[7]\n",
    "            cur_trg_type=dec_outs[8]\n",
    "            #cur_arg_type=dec_outs[9]\n",
    "\n",
    "            #rel = torch.cat((rel, cur_rel), 1)\n",
    "            trig_s = torch.cat((trig_s, cur_trig_s), 1)\n",
    "            trig_e = torch.cat((trig_e, cur_trig_e), 1)\n",
    "            ent_s = torch.cat((ent_s, cur_ent_s), 1)\n",
    "            ent_e = torch.cat((ent_e, cur_ent_e), 1)\n",
    "            trg_type = torch.cat((trg_type, cur_trg_type),1)\n",
    "            #arg_type = torch.cat((arg_type, cur_arg_type),1)\n",
    "\n",
    "            #topv, topi = cur_rel[:, :, 1:].topk(1)\n",
    "            #topi = torch.add(topi, 1)\n",
    "            #rel_topv, rel_topi = cur_rel[:, :, 1:].topk(1)\n",
    "            #rel_topi = torch.add(rel_topi, 1)\n",
    "            trg_topv, trg_topi = cur_trg_type[:, :, 1:].topk(1)\n",
    "            trg_topi = torch.add(trg_topi, 1)\n",
    "            #arg_topv, arg_topi = cur_arg_type[:, :, 1:].topk(1)\n",
    "            #arg_topi = torch.add(arg_topi, 1)\n",
    "\n",
    "        if is_training:\n",
    "            #rel = rel.view(-1, len(relnameToIdx))\n",
    "            trig_s = trig_s.view(-1, src_time_steps)\n",
    "            trig_e = trig_e.view(-1, src_time_steps)\n",
    "            ent_s = ent_s.view(-1, src_time_steps)\n",
    "            ent_e = ent_e.view(-1, src_time_steps)\n",
    "            trg_type = trg_type.view(-1, len(eventnameToIdx))\n",
    "            #arg_type = arg_type.view(-1, len(argnameToIdx))\n",
    "        #custom_print('execution complete for this batch')\n",
    "        return _, trig_s, trig_e, ent_s, ent_e, trg_type, _\n",
    "\n",
    "def get_model(model_id):\n",
    "    if model_id == 1:\n",
    "        return Seq2SeqModel()\n",
    "\n",
    "\n",
    "# In[147]:\n",
    "\n",
    "def shuffle_data(data):\n",
    "    #print(len(data))\n",
    "    custom_print(len(data))\n",
    "    data.sort(key=lambda x: x.SrcLen)\n",
    "    num_batch = int(len(data) / batch_size)\n",
    "    rand_idx = random.sample(range(num_batch), num_batch)\n",
    "    new_data = []\n",
    "    for idx in rand_idx:\n",
    "        new_data += data[batch_size * idx: batch_size * (idx + 1)]\n",
    "    if len(new_data) < len(data):\n",
    "        new_data += data[num_batch * batch_size:]\n",
    "    return new_data\n",
    "\n",
    "def predict(samples, model, model_id):\n",
    "    pred_batch_size = batch_size\n",
    "    batch_count = math.ceil(len(samples) / pred_batch_size)\n",
    "    move_last_batch = False\n",
    "    if len(samples) - batch_size * (batch_count - 1) == 1:\n",
    "        move_last_batch = True\n",
    "        batch_count -= 1\n",
    "    rel = list()\n",
    "    arg1s = list()\n",
    "    arg1e = list()\n",
    "    arg2s = list()\n",
    "    arg2e = list()\n",
    "    eType=list()\n",
    "    argType=list()\n",
    "    model.eval()\n",
    "    #set_random_seeds(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    start_time = datetime.datetime.now()\n",
    "    for batch_idx in tqdm(range(0, batch_count)):\n",
    "        batch_start = batch_idx * pred_batch_size\n",
    "        batch_end = min(len(samples), batch_start + pred_batch_size)\n",
    "        if batch_idx == batch_count - 1 and move_last_batch:\n",
    "            batch_end = len(samples)\n",
    "\n",
    "        cur_batch = samples[batch_start:batch_end]\n",
    "        cur_samples_input = get_batch_data(cur_batch, False)\n",
    "\n",
    "        src_words_seq = torch.from_numpy(cur_samples_input['src_words'].astype('long'))\n",
    "        bert_words_mask = torch.from_numpy(cur_samples_input['bert_mask'].astype('bool'))\n",
    "        #src_pos_tags = torch.from_numpy(cur_samples_input['pos_tag_seq'].astype('long'))\n",
    "        positional_seq = torch.from_numpy(cur_samples_input['positional_seq'].astype('long'))\n",
    "        src_words_mask = torch.from_numpy(cur_samples_input['src_words_mask'].astype('uint8'))\n",
    "        #trg_words_seq = torch.from_numpy(cur_samples_input['decoder_input'].astype('long'))\n",
    "        src_chars_seq = torch.from_numpy(cur_samples_input['src_chars'].astype('long'))\n",
    "        #adj = torch.from_numpy(cur_samples_input['adj'].astype('float32'))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            src_words_seq = src_words_seq.cuda()\n",
    "            bert_words_mask = bert_words_mask.cuda()\n",
    "            #src_pos_tags = src_pos_tags.cuda()\n",
    "            src_words_mask = src_words_mask.cuda()\n",
    "            #trg_words_seq = trg_words_seq.cuda()\n",
    "            src_chars_seq = src_chars_seq.cuda()\n",
    "            #adj = adj.cuda()\n",
    "            positional_seq = positional_seq.cuda()\n",
    "\n",
    "        src_words_seq = autograd.Variable(src_words_seq)\n",
    "        bert_words_mask = autograd.Variable(bert_words_mask)\n",
    "        #src_pos_tags = autograd.Variable(src_pos_tags)\n",
    "        src_words_mask = autograd.Variable(src_words_mask)\n",
    "        #trg_words_seq = autograd.Variable(trg_words_seq)\n",
    "        src_chars_seq = autograd.Variable(src_chars_seq)\n",
    "        #adj = autograd.Variable(adj)\n",
    "        positional_seq = autograd.Variable(positional_seq)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if model_id == 1:    \n",
    "                outputs = model(src_words_seq, bert_words_mask,  src_words_mask, src_chars_seq, positional_seq, max_trg_len, None, None, False)\n",
    "\n",
    "        #rel += list(outputs[0].data.cpu().numpy())\n",
    "        arg1s += list(outputs[1].data.cpu().numpy())\n",
    "        arg1e += list(outputs[2].data.cpu().numpy())\n",
    "        arg2s += list(outputs[3].data.cpu().numpy())\n",
    "        \n",
    "        arg2e += list(outputs[4].data.cpu().numpy())\n",
    "        eType += list(outputs[5].data.cpu().numpy())\n",
    "        #argType += list(outputs[6].data.cpu().numpy())\n",
    "        model.zero_grad()\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    #print('Prediction time:', end_time - start_time)\n",
    "    custom_print('Prediction time:', end_time - start_time)\n",
    "    return  arg1s, arg1e, arg2s, arg2e, eType\n",
    "def train_model(model_id, train_samples, dev_samples, best_model_file):\n",
    "    train_size = len(train_samples)\n",
    "    print('train_size')\n",
    "    print(train_size)\n",
    "    batch_count = int(math.ceil(train_size/batch_size))\n",
    "    move_last_batch = False\n",
    "    if len(train_samples) - batch_size * (batch_count - 1) == 1:\n",
    "        move_last_batch = True\n",
    "        batch_count -= 1\n",
    "    #print(batch_count)\n",
    "    custom_print(batch_count)\n",
    "    model = get_model(model_id)#call get_model(id=1)\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    #print('Parameters size:', pytorch_total_params)\n",
    "    custom_print('Parameters size:', pytorch_total_params)\n",
    "    #print(model)\n",
    "    custom_print(model)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    if n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    #rel_criterion = nn.NLLLoss(ignore_index=0)\n",
    "\n",
    "    eType_criterion = nn.NLLLoss(ignore_index=0)#\n",
    "    #aType_criterion = nn.NLLLoss(ignore_index=0)#\n",
    "\n",
    "    pointer_criterion = nn.NLLLoss(ignore_index=-1)\n",
    "    #event type classification loss***********\n",
    "    #arg type classification loss*************\n",
    "    #print('weight factor:', wf)\n",
    "    custom_print('weight factor:', wf)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "    if update_bert:\n",
    "        optimizer = AdamW(model.parameters(), lr=1e-05, correct_bias=False)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "    #custom_print(optimizer)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    #print(optimizer)\n",
    "    custom_print(optimizer)\n",
    "\n",
    "    best_dev_acc = -1.0\n",
    "    best_epoch_idx = -1\n",
    "    best_epoch_seed = -1\n",
    "    for epoch_idx in range(0, num_epoch):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        #print('Epoch:', epoch_idx + 1)\n",
    "        custom_print('Epoch:', epoch_idx + 1)\n",
    "        cur_seed = random_seed + epoch_idx + 1\n",
    "\n",
    "        torch.manual_seed(cur_seed)\n",
    "        #set_random_seeds(cur_seed)\n",
    "        cur_shuffled_train_data = shuffle_data(train_samples)#shuffle training data\n",
    "        start_time = datetime.datetime.now()\n",
    "        train_loss_val = 0.0\n",
    "\n",
    "        for batch_idx in tqdm(range(0, batch_count)):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(len(cur_shuffled_train_data), batch_start + batch_size)\n",
    "            if batch_idx == batch_count - 1 and move_last_batch:\n",
    "                batch_end = len(cur_shuffled_train_data)\n",
    "\n",
    "            cur_batch = cur_shuffled_train_data[batch_start:batch_end]\n",
    "            cur_samples_input = get_batch_data(cur_batch, True)#call get_batch_data()\n",
    "\n",
    "            '''\n",
    "            Each record of cur_samples_input{} holds\n",
    "            {'src_words': np.array(src_words_list, dtype=np.float32),#list of word_index\n",
    "            'positional_seq': np.array(positional_index_list),#list of word_position_index\n",
    "            'src_words_mask': np.array(src_words_mask_list),#list of source word masks [0,0,0,1,1]\n",
    "            'src_chars': np.array(src_char_seq),#list of source character sequences with padding for CNN operation\n",
    "            'decoder_input': np.array(decoder_input_list),#list of all the relation indexes present in the trg_seq padded till amx_trg_len(for training), [] for testing\n",
    "            'adj': np.array(adj_lst),\n",
    "            'rel': np.array(rel_seq),#list of relation seq padded till max_trg_len\n",
    "            'arg1_start':np.array(arg1_start_seq),#list of all the start index of the first entities (present in the trg_seq of len max_trg_len) padded with -1\n",
    "            'arg1_end': np.array(arg1_end_seq),#list of all the last index of the first entities (present in the trg_seq of len max_trg_len) padded with -1\n",
    "            'arg2_start': np.array(arg2_start_seq),#list of all the start index of the second entities (present in the trg_seq of len max_trg_len) padded with -1\n",
    "            'arg2_end': np.array(arg2_end_seq),#list of all the last index of the second entities (present in the trg_seq of len max_trg_len) padded with -1\n",
    "            'arg1_mask': np.array(arg1_mask_seq),#list of entity_1 mask, it's a list of size max_trg_len. and each item  is a list of size max_src_len, all 1 but the entity_1's start and end pos is 0.\n",
    "            'arg2_mask': np.array(arg2_mask_seq)}#list of entity_2 mask,...\n",
    "            }\n",
    "            '''\n",
    "\n",
    "            src_words_seq = torch.from_numpy(cur_samples_input['src_words'].astype('long'))#[23,45,1,56,78,..,0,0,..]\n",
    "            bert_words_mask = torch.from_numpy(cur_samples_input['bert_mask'].astype('bool'))\n",
    "            #src_pos_tags = torch.from_numpy(cur_samples_input['pos_tag_seq'].astype('long'))##\n",
    "            positional_seq = torch.from_numpy(cur_samples_input['positional_seq'].astype('long'))#[1,2,3,4,..,0,0,...]\n",
    "            src_words_mask = torch.from_numpy(cur_samples_input['src_words_mask'].astype('bool'))#[0,0,0,0,0,1,1,1,..]\n",
    "           # trg_words_seq = torch.from_numpy(cur_samples_input['decoder_input'].astype('long'))#[2,5,1,6,id('none'),id(pad),id(pad),..]\n",
    "            src_chars_seq = torch.from_numpy(cur_samples_input['src_chars'].astype('long'))#[0,0,3,4,5,0,0,12,2,3,4,0,0,....]\n",
    "            et_seq=torch.from_numpy(cur_samples_input['event'])#\n",
    "            #arg_seq=torch.from_numpy(cur_samples_input['arg'])#\n",
    "            #rel = torch.from_numpy(cur_samples_input['rel'].astype('long'))#same as trg_words_seq\n",
    "            trigger_s = torch.from_numpy(cur_samples_input['trigger_start'].astype('long'))#[3,3,7,-1,-1,-1,..]\n",
    "            trigger_e = torch.from_numpy(cur_samples_input['trigger_end'].astype('long'))#[5,5,10,-1,-1,-1,..]\n",
    "            entity_s = torch.from_numpy(cur_samples_input['entity_start'].astype('long'))#[9,9,14,-1,-1,..]\n",
    "            entity_e = torch.from_numpy(cur_samples_input['entity_end'].astype('long'))#[12,12,17,-1,-1,-1,..]\n",
    "\n",
    "            trigger_mask = torch.from_numpy(cur_samples_input['trigger_mask'].astype('uint8'))# [[0,0,1,1,1,1,1,1,..],[1,1,0,1,1,0,1,1...],[...]]\n",
    "            entity_mask = torch.from_numpy(cur_samples_input['entity_mask'].astype('uint8'))# [[1,1,0,0,1,1,1,1,..],[1,1,0,1,0,1,1,1...],[...]]\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                src_words_seq = src_words_seq.cuda()\n",
    "                bert_words_mask = bert_words_mask.cuda()\n",
    "                #src_pos_tags = src_pos_tags.cuda()\n",
    "                src_words_mask = src_words_mask.cuda()\n",
    "               # trg_words_seq = trg_words_seq.cuda()\n",
    "                src_chars_seq = src_chars_seq.cuda()\n",
    "                #adj = adj.cuda()\n",
    "                positional_seq = positional_seq.cuda()\n",
    "\n",
    "                #rel = rel.cuda()\n",
    "                et_seq = et_seq.cuda()\n",
    "                #arg_seq = arg_seq.cuda()\n",
    "\n",
    "                trigger_s = trigger_s.cuda()\n",
    "                trigger_e = trigger_e.cuda()\n",
    "                entity_s = entity_s.cuda()\n",
    "                entity_e = entity_e.cuda()\n",
    "\n",
    "                trigger_mask = trigger_mask.cuda()\n",
    "                entity_mask = entity_mask.cuda()\n",
    "\n",
    "            src_words_seq = autograd.Variable(src_words_seq)\n",
    "            bert_words_mask = autograd.Variable(bert_words_mask)\n",
    "            #src_pos_tags = autograd.Variable(src_pos_tags)\n",
    "            src_words_mask = autograd.Variable(src_words_mask)\n",
    "            #trg_words_seq = autograd.Variable(trg_words_seq)\n",
    "            src_chars_seq = autograd.Variable(src_chars_seq)\n",
    "            #adj = autograd.Variable(adj)\n",
    "            positional_seq = autograd.Variable(positional_seq)\n",
    "\n",
    "            #rel = autograd.Variable(rel)\n",
    "            et_seq = autograd.Variable(et_seq)#\n",
    "            #arg_seq = autograd.Variable(arg_seq)#\n",
    "            trigger_s = autograd.Variable(trigger_s)\n",
    "            trigger_e = autograd.Variable(trigger_e)\n",
    "            entity_s = autograd.Variable(entity_s)\n",
    "            entity_e = autograd.Variable(entity_e)\n",
    "\n",
    "            trigger_mask = autograd.Variable(trigger_mask)\n",
    "            entity_mask = autograd.Variable(entity_mask)  \n",
    "\n",
    "\n",
    "            ##outputs = model(src_words_seq, bert_words_mask, src_pos_tags, src_words_mask, src_chars_seq, positional_seq, trg_words_seq, rel.size()[1], trigger_mask, entity_mask, True)# call seq2seqmodel()  \n",
    "            outputs = model(src_words_seq, bert_words_mask,src_words_mask, src_chars_seq, positional_seq,et_seq.size()[1],trigger_mask, entity_mask, True)# call seq2seqmodel()\n",
    "\n",
    "            #rel = rel.view(-1, 1).squeeze()\n",
    "            arg1s = trigger_s.view(-1, 1).squeeze()\n",
    "            arg1e = trigger_e.view(-1, 1).squeeze()\n",
    "            arg2s = entity_s.view(-1, 1).squeeze()\n",
    "            arg2e = entity_e.view(-1, 1).squeeze()\n",
    "            et_seq = et_seq.view(-1, 1).squeeze()#\n",
    "            #arg_seq = arg_seq.view(-1, 1).squeeze()#\n",
    "\n",
    "            loss = eType_criterion(outputs[5], et_seq) +   wf * (pointer_criterion(outputs[1], arg1s) + pointer_criterion(outputs[2], arg1e)) +  wf * (pointer_criterion(outputs[3], arg2s) + pointer_criterion(outputs[4], arg2e))\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "            if (batch_idx + 1) % update_freq == 0:\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "            train_loss_val += loss.item()\n",
    "\n",
    "        train_loss_val /= batch_count\n",
    "        end_time = datetime.datetime.now()\n",
    "        #print('Training loss:', train_loss_val)\n",
    "        #print('Training time:', end_time - start_time)\n",
    "        custom_print('Training loss:', train_loss_val)\n",
    "        custom_print('Training time:', end_time - start_time)\n",
    "\n",
    "        #print('\\nDev Results\\n')\n",
    "        custom_print('\\nDev Results\\n')\n",
    "        #set_random_seeds(random_seed)\n",
    "        torch.manual_seed(cur_seed)#newly added\n",
    "\n",
    "        dev_preds = predict(dev_samples, model, model_id)# call predict()\n",
    "\n",
    "        pred_pos, gt_pos, correct_pos = get_F1(dev_samples, dev_preds)\n",
    "        #print(pred_pos, '\\t', gt_pos, '\\t', correct_pos)\n",
    "        custom_print(pred_pos, '\\t', gt_pos, '\\t', correct_pos)\n",
    "        p = float(correct_pos) / (pred_pos + 1e-8)\n",
    "        r = float(correct_pos) / (gt_pos + 1e-8)\n",
    "        dev_acc = (2 * p * r) / (p + r + 1e-8)\n",
    "        #print('F1:', dev_acc)\n",
    "        custom_print('F1:', dev_acc)\n",
    "\n",
    "        if dev_acc >= best_dev_acc:\n",
    "            best_epoch_idx = epoch_idx + 1\n",
    "            best_epoch_seed = cur_seed\n",
    "            #custom_print('model saved......')\n",
    "            #print('model saved......')\n",
    "            custom_print('model saved......')\n",
    "            best_dev_acc = dev_acc\n",
    "            torch.save(model.state_dict(), best_model_file)\n",
    "\n",
    "        #print('\\n\\n')\n",
    "        custom_print('\\n\\n')\n",
    "        if epoch_idx + 1 - best_epoch_idx >= early_stop_cnt:\n",
    "            break\n",
    "\n",
    "    #print('*******')\n",
    "    #print('Best Epoch:', best_epoch_idx)\n",
    "    #print('Best Epoch Seed:', best_epoch_seed)\n",
    "\n",
    "    custom_print('*******')\n",
    "    custom_print('Best Epoch:', best_epoch_idx)\n",
    "    custom_print('Best Epoch Seed:', best_epoch_seed)\n",
    "\n",
    "n_gpu = torch.cuda.device_count()\n",
    "random_seed=1023\n",
    "torch.manual_seed(random_seed)\n",
    "#set_random_seeds(random_seed)\n",
    "batch_size = 32\n",
    "num_epoch = 100\n",
    "model_name=1\n",
    "\n",
    "logger = open('test_18_10.log', 'w+')\n",
    "\n",
    "bert_base_size = 768\n",
    "update_bert = 0\n",
    "bert_model_name = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_basic_tokenize=False)\n",
    "\n",
    "max_src_len = 140#max sentence length = 135\n",
    "max_trg_len = 23#max number of tuple\n",
    "embedding_file = '/content/drive/MyDrive/w2v.txt'#pretrained word embeddings file\n",
    "word_embed_dim = 300\n",
    "word_min_freq = 2\n",
    "\n",
    "char_embed_dim = 50\n",
    "char_feature_size = 50\n",
    "\n",
    "pos_embed_dim=50\n",
    "\n",
    "conv_filter_size = 3\n",
    "max_word_len = 10\n",
    "positional_embed_dim = word_embed_dim\n",
    "#max_positional_idx = 100\n",
    "max_positional_idx = 140\n",
    "\n",
    "enc_inp_size = bert_base_size + char_feature_size  ###pos_embed_dim + \n",
    "enc_hidden_size = word_embed_dim\n",
    "dec_inp_size = enc_hidden_size\n",
    "dec_hidden_size = dec_inp_size\n",
    "\n",
    "drop_rate = 0.5\n",
    "enc_type = ['LSTM', 'GCN', 'LSTM-GCN'][0]\n",
    "att_type = 2\n",
    "wf = 1.0\n",
    "update_freq = 1\n",
    "use_hadamard = False\n",
    "early_stop_cnt = 7\n",
    "\n",
    "Sample = recordclass(\"Sample\", \"Id SrcLen SrcWords  eventTypes  TrgPointers  TrgLen\")\n",
    "\n",
    "event_file = '/content/event_names.txt'\n",
    "eventnameToIdx, eventIdxToName=get_events(event_file)#return event dictionary\n",
    "\n",
    "print(eventnameToIdx,eventnameToIdx)\n",
    "\n",
    "\n",
    "custom_print(max_src_len, '\\t', max_trg_len, '\\t', drop_rate)\n",
    "custom_print(batch_size, '\\t', num_epoch)\n",
    "custom_print(enc_type)\n",
    "custom_print('loading data......')\n",
    "\n",
    "\n",
    "src_train_file = '/content/train_bert.sent'\n",
    "trg_train_file = '/content/train_bert.pointer'\n",
    "#pos_train_file = 'train_bert.pos'\n",
    "\n",
    "train_data = read_data(src_train_file, trg_train_file, 1)#call read_data() for train_set\n",
    "\n",
    "src_dev_file = '/content/dev_bert.sent'\n",
    "trg_dev_file = '/content/dev_bert.pointer'\n",
    "#pos_dev_file = 'dev_bert.pos'\n",
    "dev_data = read_data(src_dev_file, trg_dev_file, 2)#call read_data() for dev_set\n",
    "\n",
    "src_test_file = '/content/test_bert.sent'\n",
    "trg_test_file = '/content/test_bert.pointer'\n",
    "#pos_test_file = 'test_bert.pos'\n",
    "test_data = read_data(src_test_file, trg_test_file, 3)#call read_data() for dev_set\n",
    "\n",
    "\n",
    "custom_print('Training data size:', len(train_data))\n",
    "custom_print('Development data size:', len(dev_data))\n",
    "\n",
    "custom_print(\"preparing vocabulary......\")\n",
    "\n",
    "save_vocab = '/content/vocab.pkl'\n",
    "custom_print(\"getting pos tags......\")\n",
    "#print(\"getting pos tags......\")\n",
    "#pos_vocab = build_tags(pos_train_file, pos_dev_file, pos_test_file)\n",
    "\n",
    "word_vocab, char_vocab, word_embed_matrix = build_vocab(train_data, dev_data, test_data, save_vocab, embedding_file)#create vocabulary and word embeddings\n",
    "\n",
    "#print(\"Training started......\")\n",
    "#custom_print(\"Training started......\")\n",
    "\n",
    "#model_name=1\n",
    "#model_file_name = 'model_bert_update.h5py'\n",
    "\n",
    "#train_model(model_name, train_data, dev_data, model_file_name)#call train_model()\n",
    "\n",
    "custom_print(\"loading word vectors......\")\n",
    "vocab_file_name = '/content/vocab.pkl'\n",
    "word_vocab, char_vocab= load_vocab(vocab_file_name)\n",
    "\n",
    "custom_print('vocab size:', len(word_vocab))\n",
    "\n",
    "model_file = '/content/drive/MyDrive/model_bert_19_10.h5py'\n",
    "\n",
    "best_model = get_model(model_name)\n",
    "custom_print(best_model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    best_model.cuda()\n",
    "if n_gpu > 1:\n",
    "    best_model = torch.nn.DataParallel(best_model)\n",
    "best_model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "custom_print('\\nTest Results\\n')\n",
    "#print('\\nTest Results\\n')\n",
    "src_test_file = 'test_bert.sent'\n",
    "trg_test_file = 'test_bert.pointer'\n",
    "#pos_test_file = 'test_bert.pos'\n",
    "test_data = read_data(src_test_file, trg_test_file, 3)\n",
    "\n",
    "\n",
    "#reader = open(os.path.join(src_data_folder, 'test_trim_14.tup'))\n",
    "#test_gt_lines = reader.readlines()\n",
    "#reader.close()\n",
    "\n",
    "\n",
    "sent_reader=open('test_bert.sent','r')\n",
    "test_sent_lines = sent_reader.readlines()\n",
    "sent_reader.close()\n",
    "\n",
    "custom_print('Test size:', len(test_data))\n",
    "\n",
    "test_preds = predict(test_data, best_model, model_name)\n",
    "pred_pos, gt_pos, correct_pos, ti, tc, ai, ro = get_F1(test_data, test_preds)\n",
    "custom_print(pred_pos, '\\t', gt_pos, '\\t', correct_pos)\n",
    "\n",
    "custom_print('no of correctly identified triggers= '+str(ti))\n",
    "custom_print('no of correctly classified triggers= '+str(tc))\n",
    "custom_print('no of correctly identified arguments= '+str(ai))\n",
    "custom_print('no of correctly identified roles= '+str(ro))\n",
    "\n",
    "p = float(correct_pos) / (pred_pos + 1e-8)\n",
    "r = float(correct_pos) / (gt_pos + 1e-8)\n",
    "test_acc = (2 * p * r) / (p + r + 1e-8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_ti = float(ti) / (pred_pos + 1e-8)\n",
    "r_ti = float(ti) / (gt_pos + 1e-8)\n",
    "ti_test_acc = (2 * p_ti * r_ti) / (p_ti + r_ti + 1e-8)\n",
    "\n",
    "p_tc = float(tc) / (pred_pos + 1e-8)\n",
    "r_tc = float(tc) / (gt_pos + 1e-8)\n",
    "tc_test_acc = (2 * p_tc * r_tc) / (p_tc + r_tc + 1e-8)\n",
    "\n",
    "p_ai = float(ai) / (pred_pos + 1e-8)\n",
    "r_ai = float(ai) / (gt_pos + 1e-8)\n",
    "ai_test_acc = (2 * p_ai * r_ai) / (p_ai + r_ai + 1e-8)\n",
    "\n",
    "p_ro = float(ro) / (pred_pos + 1e-8)\n",
    "r_ro = float(ro) / (gt_pos + 1e-8)\n",
    "ro_test_acc = (2 * p_ro * r_ro) / (p_ro + r_ro + 1e-8)\n",
    "\n",
    "custom_print('P_tuple:', round(p, 3))\n",
    "custom_print('P_ti:', round(p_ti, 3))\n",
    "custom_print('P_tc:', round(p_tc, 3))\n",
    "custom_print('P_ai:', round(p_ai, 3))\n",
    "custom_print('P_ro:', round(p_ro, 3))\n",
    "\n",
    "custom_print('R_tuple:', round(r, 3))\n",
    "custom_print('R_ti:', round(r_ti, 3))\n",
    "custom_print('R_tc:', round(r_tc, 3))\n",
    "custom_print('R_ai:', round(r_ai, 3))\n",
    "custom_print('R_ro:', round(r_ro, 3))\n",
    "\n",
    "custom_print('F1:', round(test_acc, 3))\n",
    "custom_print('TI F1:', round(ti_test_acc,3))\n",
    "custom_print('TC F1:', round(tc_test_acc,3))\n",
    "custom_print('AI F1:', round(ai_test_acc,3))\n",
    "custom_print('RL F1:', round(ro_test_acc,3))\n",
    "\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6T99hEkq3SNQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
